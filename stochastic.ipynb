{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XgUdyonIRpMb",
        "y1flpzoQFTVa",
        "8chCbs1o_Iud",
        "8idRoUCpsoKR",
        "vUbYRNP_zXe4",
        "m0K1gPOoznzE",
        "LVOw3me6qbku",
        "DAdF2iW5biD_",
        "H6kSAH20bmvm",
        "s9HF-07Hbona",
        "Frb1ShYDbqfh",
        "QyRDpo40btSe"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deltorobarba/finance/blob/main/stochastic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <font color=\"blue\">**Stochastic**"
      ],
      "metadata": {
        "id": "KaRe47oJEybG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Probability Theory & Loss Functions*"
      ],
      "metadata": {
        "id": "XgUdyonIRpMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss functions that belong to the category \"distance-based\" are primarily used in regression problems. They utilize the numeric difference between the predicted output and the true target as a proxy variable to quantify the quality of individual predictions.\n",
        "\n",
        "> Great overview: http://juliaml.github.io/LossFunctions.jl/stable/losses/distance/\n",
        "\n",
        "![xx](https://raw.githubusercontent.com/deltorobarba/repo/master/regression_loss.PNG)\n",
        "\n"
      ],
      "metadata": {
        "id": "bmOIiW0sRpMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(Linear) Least Squares**\n",
        "\n",
        "* Least Squares: Deren Parameter werden so bestimmt, dass die Summe der Abweichungsquadrate e der Beobachtungen y von den Werten der Funktion minimiert wird.\n",
        "\n",
        "* Da die Kleinste-Quadrate-Sch√§tzung die Residuenquadratsumme minimiert, ist es dasjenige Sch√§tzverfahren, welches das [Bestimmtheitsma√ü](https://de.wikipedia.org/wiki/Bestimmtheitsma√ü) maximiert.\n",
        "\n",
        "* Das Bestimmtheitsma√ü der Regression, auch empirisches Bestimmtheitsma√ü, ist eine dimensionslose Ma√üzahl die den Anteil der Variabilit√§t in den Messwerten der abh√§ngigen Variablen ausdr√ºckt, der durch das lineare Modell ‚Äûerkl√§rt‚Äú wird. Mithilfe dieser Definition k√∂nnen die Extremwerte f√ºr das Bestimmtheitsma√ü aufgezeigt werden. F√ºr das\n",
        "Bestimmtheitsma√ü gilt, dass es umso nƒÉher am Wert 1 ist, je kleiner die Residuenquadratsumme ist. Es wird maximal gleich 1 wenn $\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}=0$ ist, also alle Residuen null sind. In diesem Fall ist die Anpassung an die Daten perfekt, was bedeutet, dass f√ºr jede Beobachtung $y_{i}=\\hat{y}_{i}$ ist.\n",
        "\n",
        "* [Least Squares](https://en.wikipedia.org/wiki/Least_squares) / [Methode der kleinsten Quadrate](https://de.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate) & [Linear Least Squares](https://en.wikipedia.org/wiki/Linear_least_squares)"
      ],
      "metadata": {
        "id": "ybpZTameRpMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Gauss‚ÄìMarkov theorem (BLUE)**\n",
        "\n",
        "*  states that the ordinary least squares (OLS) estimator has the lowest sampling variance within the class of linear unbiased estimators, **if the errors in the linear regression model are uncorrelated, have equal variances and expectation value of zero**.\n",
        "\n",
        "* stellt eine theoretische Rechtfertigung der Methode der kleinsten Quadrate dar\n",
        "\n",
        "* Der Satz besagt, dass in einem linearen Regressionsmodell, in dem die **St√∂rgr√∂√üen (error term) einen Erwartungswert von null und eine konstante Varianz haben sowie unkorreliert sind** (Annahmen des klassischen linearen Regressionsmodells), der Kleinste-Quadrate-Sch√§tzer ‚Äì vorausgesetzt er existiert ‚Äì ein bester linearer erwartungstreuer Sch√§tzer ist (englisch Best Linear Unbiased Estimator, kurz: BLUE).\n",
        "\n",
        "* Hierbei bedeutet der ‚Äûbeste‚Äú, dass er ‚Äì innerhalb der Klasse der linearen erwartungstreuen Sch√§tzer ‚Äì die ‚Äûkleinste‚Äú Kovarianzmatrix aufweist und somit minimalvariant ist. Die St√∂rgr√∂√üen m√ºssen nicht notwendigerweise normalverteilt sein. Sie m√ºssen im Fall der verallgemeinerten Kleinste-Quadrate-Sch√§tzung auch nicht unabh√§ngig und identisch verteilt sein.\n",
        "\n",
        "The Gauss-Markov assumptions concern the set of error random variables, $\\varepsilon_{i}:$\n",
        "\n",
        "1. They have mean zero: $\\mathrm{E}\\left[\\varepsilon_{i}\\right]=0$\n",
        "\n",
        "2. They are homoscedastic, that is all have the same finite variance: $\\operatorname{Var}\\left(\\varepsilon_{i}\\right)=\\sigma^{2}<\\infty$ for all $i$,\n",
        "3. Distinct error terms are uncorrelated: $\\operatorname{Cov}\\left(\\varepsilon_{i}, \\varepsilon_{j}\\right)=0, \\forall i \\neq j$.\n",
        "\n",
        "A linear estimator of $\\beta_{j}$ is a linear combination $\\widehat{\\beta}_{j}=c_{1 j} y_{1}+\\cdots+c_{n j} y_{n}$\n",
        "\n",
        "* The errors do not need to be normal, nor do they need to be independent and identically distributed (only uncorrelated with mean zero and homoscedastic with finite variance).\n",
        "\n",
        "* The requirement that the estimator be unbiased cannot be dropped, since biased estimators exist with lower variance. See, for example, the [James‚ÄìStein estimator](https://en.wikipedia.org/wiki/James‚ÄìStein_estimator) (which also drops linearity), [ridge regression(Tikhonov_regularization)](https://en.wikipedia.org/wiki/Tikhonov_regularization), or simply any [degenerate estimator](https://en.wikipedia.org/wiki/Degenerate_distribution).\n",
        "\n",
        "* https://en.wikipedia.org/wiki/Gauss‚ÄìMarkov_theorem"
      ],
      "metadata": {
        "id": "l0xBPcNPRpMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ordinary Least Squares (OLS)**\n",
        "\n",
        "* Ordinary least squares is a type of linear least squares method for estimating the unknown parameters in a linear regression model.\n",
        "\n",
        "* ‚ÄúOrdinary Least Squares‚Äù (OLS) method is used to find the best line intercept (b) and the slope (m). [in y = mx + b, m is the slope and b the intercept]\n",
        "\n",
        "\n",
        "> $m=\\frac{\\sum\\left(x_{i}-\\bar{x}\\right)\\left(y_{i}-\\bar{y}\\right)}{\\sum\\left(x_{i}-\\bar{x}\\right)^{2}}$\n",
        "\n",
        "> $b=\\bar{y}-m * \\bar{x}$\n",
        "\n",
        "* In other words ‚Üí with OLS Linear Regression the goal is to find the line (or hyperplane) that minimizes the vertical offsets. We define the best-fitting line as the line that minimizes the sum of squared errors (SSE) or mean squared error (MSE) between our target variable (y) and our predicted output over all samples i in our dataset of size n.\n",
        "\n",
        "* OLS chooses the parameters of a linear function of a set of explanatory variables by the principle of least squares: minimizing the sum of the squares of the differences between the observed dependent variable (values of the variable being observed) in the given dataset and those predicted by the linear function\n",
        "\n",
        "* The OLS method minimizes the sum of squared residuals, and leads to a [closed-form expression](https://en.wikipedia.org/wiki/Closed-form_expression) for the estimated value of the unknown parameter vector Œ≤.\n",
        "\n",
        "* It is important to point out though that OLS method will work for a univariate dataset (ie., single independent variables and single dependent variables). Multivariate dataset contains a single independent variables set and multiple dependent variables sets, requiring a machine learning algorithm called ‚ÄúGradient Descent‚Äù.\n",
        "\n",
        "* [Wiki](https://en.wikipedia.org/wiki/Ordinary_least_squares) & [Medium](https://medium.com/@jorgesleonel/linear-regression-307937441a8b)"
      ],
      "metadata": {
        "id": "Io8XPm78RpMb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weighted Least Squares (WLS)**\n",
        "\n",
        "* are used when heteroscedasticity is present in the error terms of the model.\n",
        "* https://en.wikipedia.org/wiki/Weighted_least_squares"
      ],
      "metadata": {
        "id": "BhP9nZcTRpMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generalized Least Squares (GLS)**\n",
        "\n",
        "* is an extension of the OLS method, that **allows efficient estimation of Œ≤ when either heteroscedasticity, or correlations, or both are present among the error terms of the model**, as long as the form of heteroscedasticity and correlation is known independently of the data.\n",
        "\n",
        "* To handle heteroscedasticity when the error terms are uncorrelated with each other, GLS minimizes a weighted analogue to the sum of squared residuals from OLS regression, where the weight for the ith case is inversely proportional to var(Œµi). This special case of GLS is called \"weighted least squares\".\n",
        "\n",
        "* https://en.wikipedia.org/wiki/Generalized_least_squares"
      ],
      "metadata": {
        "id": "nNbrVPssRpMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SE, SAE & SSE**\n",
        "\n",
        "**Sum of Errors (SE)** the difference in the predicted value and the actual value.\n",
        "\n",
        "$\\mathbf{L}=\\Sigma(\\hat{Y}-Y)$\n",
        "\n",
        "Errors terms cancel each other out.\n",
        "\n",
        "**Sum of Absolute Errors (SAE)** takes the absolute values of the errors for all iterations.\n",
        "\n",
        "$\\mathbf{L}=\\Sigma (|\\hat{Y}-Y|)$\n",
        "\n",
        "This loss function is not differentiable at 0.\n",
        "\n",
        "**Sum of Squared Errors (SSE)** is differentiable at all points and gives non-negative errors. But you could argue that why cannot we go for higher orders like 4th order or so. Then what if we consider to take 4th order loss function, which would look like:\n",
        "\n",
        "$\\mathbf{L}=\\left[\\Sigma(\\hat{Y}-Y)^{2}\\right]$\n",
        "\n",
        "The gradient of the loss function will vanish at minima & maxima. And the error will grow with the sample size.\n",
        "\n",
        "![xxx](https://raw.githubusercontent.com/deltorobarba/repo/master/sumoferrors.png)\n",
        "\n",
        "* Minimizing Sum of Squared Errors / SSE ([wiki](https://de.m.wikipedia.org/wiki/Residuenquadratsumme) and [medium](https://medium.com/@dustinstansbury/cutting-your-losses-loss-functions-the-sum-of-squared-errors-loss-4c467d52a511)).  We can think of the SSE loss as the (unscaled) variance of the model errors.\n",
        "* Therefore **minimizing the SEE loss is equivalent to minimizing the variance of the model residuals**. For this reason, the sum of squares loss is often referred to as the Residual Sum of Squares error (RSS) for linear models. We can think of minimizing the SSE loss as maximizing the covariance between the real outputs and those predicted by the model.\n",
        "* Ideal when distribution of residuals in normal: the [Gauss-Markov theorem](https://en.wikipedia.org/wiki/Gauss‚ÄìMarkov_theorem) states that if errors of a linear function are distributed Normally about the mean of the line, then the LSS solution gives the [best unbiased estimator](https://en.wikipedia.org/wiki/Bias_of_an_estimator) for the parameters .\n",
        "* Problem: Because each error is squared, any outliers in the dataset can dominate the parameter estimation process. For this reason, the LSS loss is said to lack robustness. Therefore preprocessing of the the dataset (i.e. removing or thresholding outlier values) may be necessary when using the LSS loss\n"
      ],
      "metadata": {
        "id": "xG8zVgjpRpMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MSE (L2) & RMSE (Squared Euclidean Distance)**\n",
        "\n",
        "* Squared Euclidean distance is of central importance in estimating parameters of statistical models, where it is used in the method of least squares, a standard approach to regression analysis.\n",
        "\n",
        "* The corresponding loss function is the squared error loss (SEL), and places progressively greater weight on larger errors. The corresponding risk function (expected loss) is mean squared error (MSE).\n",
        "\n",
        "* **Squared Euclidean distance is not a metric**, as it does not satisfy the triangle inequality. However, **it is a more general notion of distance, namely a divergence** (specifically a Bregman divergence), and can be used as a statistical distance.\n",
        "\n",
        "https://en.m.wikipedia.org/wiki/Euclidean_distance#Squared_Euclidean_distance\n",
        "\n",
        "![bb](https://upload.wikimedia.org/wikipedia/commons/thumb/1/13/3d-function-2.svg/566px-3d-function-2.svg.png)\n",
        "\n",
        "*A paraboloid, the graph of squared Euclidean distance from the origin*\n",
        "\n",
        "![bb](https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/3d-function-5.svg/566px-3d-function-5.svg.png)\n",
        "\n",
        "*A cone, the graph of Euclidean distance from the origin in the plane*"
      ],
      "metadata": {
        "id": "siZNV3XNRpMc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean Squared Error**\n",
        "\n",
        "$\\mathrm{MSE}={\\frac{1}{n} \\sum_{j=1}^{n}\\left(y_{j}-\\hat{y}_{j}\\right)^{2}}$\n",
        "\n",
        "* Mean Squared Error (L2 or Quadratic Loss). Error decreases as we increase our sample data as the distribution of our data becomes more and more narrower (referring to normal distribution). The more data we have, the less is the error.\n",
        "* Can range from 0 to ‚àû and are indifferent to the direction of errors. It is  negatively-oriented scores, which means lower values are better. It is always non ‚Äì negative and values close to zero are better. The MSE is the second moment of the error (about the origin) and thus incorporates both the variance of the estimator and its bias.\n",
        "* Problem: Sensitive to outliers and the order of loss is more than that of the data. As my data is of order 1 and the loss function, MSE has an order of 2 (squared). So we cannot directly correlate data with the error.\n",
        "* [Wikipedia](https://de.m.wikipedia.org/wiki/Methode_der_kleinsten_Quadrate)\n",
        "\n",
        "**Mean Squared Logarithmic Error (MSLR)**\n",
        "\n",
        "* Mean Squared Logarithmic Error\n",
        "* https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanSquaredLogarithmicError\n",
        "\n",
        "**RMSE** (Root-Mean-Square Error)\n",
        "\n",
        "$\\mathrm{RMSE}=\\sqrt{\\frac{1}{n} \\sum_{j=1}^{n}\\left(y_{j}-\\hat{y}_{j}\\right)^{2}}$\n",
        "\n",
        "* Root-Mean-Square Error is the distance, on average, of a data point from the fitted line, measured along a vertical line.\n",
        "* The **RMSE is directly interpretable in terms of measurement units**, and so is a better measure of goodness of fit than a correlation coefficient. One can compare the RMSE to observed variation in measurements of a typical point. The two should be similar for a reasonable fit. Metric can range from 0 to ‚àû and are indifferent to the direction of errors. It is  negatively-oriented scores, which means lower values are better.\n",
        "* Since the errors are squared before they are averaged, the RMSE gives a relatively high weight to large errors. This means the RMSE should be more useful when large errors are particularly undesirable\n",
        "* https://www.sciencedirect.com/science/article/pii/S096014811831231X\n",
        "* The **RMSE is more appropriate to represent model performance than the MAE when the error distribution is expected to be Gaussian**.\n",
        "https://www.geosci-model-dev-discuss.net/7/C473/2014/gmdd-7-C473-2014-supplement.pdf\n",
        "* When both metrics are calculated, the MAE tends to be much smaller than the RMSE because the RMSE penalizes large errors while the MAE gives the same weight to all errors.\n",
        "* They summarized that the **RMSE tends to become increasingly larger than the MAE** (but not necessarily in a monotonic fashion) as the distribution of error magnitudes becomes more variable. The RMSE tends to 1 grow larger than the MAE with n2 since its lower limit is fixed at the MAE and its upper 11 limit (n2 ¬∑ MAE) increases with n2 .\n",
        "* [Wiki](https://en.m.wikipedia.org/wiki/Root-mean-square_deviation) & [Keras](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/RootMeanSquaredError)"
      ],
      "metadata": {
        "id": "L_hXqjauRpMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAE (L1) & MAPE**\n",
        "\n",
        "$\\mathrm{MAE}=\\frac{1}{n} \\sum_{j=1}^{n}\\left|y_{j}-\\hat{y}_{j}\\right|$\n",
        "\n",
        "* If the absolute value is not taken (the signs of the errors are not removed), the average error becomes the Mean Bias Error (MBE) and is usually intended to measure average model bias. MBE can convey useful information, but should be interpreted cautiously because positive and negative errors will cancel out.\n",
        "\n",
        "* Mean Absolute Error (L1 Loss)\n",
        "* Computes the mean of absolute difference between labels and predictions\n",
        "* measures the average magnitude of the errors in a set of predictions, without considering their direction. It‚Äôs the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight.\n",
        "* On some regression problems, the **distribution of the target variable may be mostly Gaussian, but may have outliers**, e.g. large or small values far from the mean value. The Mean Absolute Error, or MAE, loss is an appropriate loss function in this case as it is more robust to outliers. It is calculated as the average of the absolute difference between the actual and predicted values.\n",
        "* Metric can range from 0 to ‚àû and are indifferent to the direction of errors. It is  negatively-oriented scores, which means lower values are better.\n",
        "* Extremwerte als Ausrei√üer mit geringerem Einfluss auf das Modell ansehen: MAE loss is useful if the training data is corrupted with outliers (i.e. we erroneously receive unrealistically huge negative/positive values in our training environment, but not our testing environment).\n"
      ],
      "metadata": {
        "id": "6WWtt8-3RpMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAE vs MSE**\n",
        "\n",
        "* One big problem in using MAE loss (for neural nets especially) is that its gradient is the same throughout, which means the gradient will be large even for small loss values.\n",
        "\n",
        "* This isn‚Äôt good for learning. To fix this, we can use dynamic learning rate which decreases as we move closer to the minima. MSE behaves nicely in this case and will converge even with a fixed learning rate.\n",
        "\n",
        "* The gradient of MSE loss is high for larger loss values and decreases as loss approaches 0, making it more precise at the end of training (see figure below.)\n",
        "\n",
        "![xx](https://raw.githubusercontent.com/deltorobarba/repo/master/mae_vs_mse.PNG)"
      ],
      "metadata": {
        "id": "MsW3oJwSRpMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean Absolute Percentage Error (MAPE)**\n",
        "\n",
        "$\\mathrm{M}=\\frac{1}{n} \\sum_{t=1}^{n}\\left|\\frac{A_{t}-F_{t}}{A_{t}}\\right|$\n",
        "\n",
        "* The mean absolute percentage error (MAPE) is a statistical measure of **how accurate a forecast** system is.\n",
        "\n",
        "* It measures this accuracy as a percentage, and can be calculated as the average absolute percent error for each time period minus actual values divided by actual values. Where At is the actual value and Ft is the forecast value.\n",
        "\n",
        "* The mean absolute percentage error (MAPE) is the most common measure used to forecast error, and works best if there are no extremes to the data (and no zeros).\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Mean_absolute_percentage_error"
      ],
      "metadata": {
        "id": "-6ZmPJnMRpMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Symmetric Mean Absolute Percentage Error (sMAPE)**\n",
        "\n",
        "* There are 3 different definitions of sMAPE. Two of them are below:\n",
        "\n",
        "$\\operatorname{SMAPE}=\\frac{100 \\%}{n} \\sum_{t=1}^{n} \\frac{\\left|F_{t}-A_{t}\\right|}{\\left(\\left|A_{t}\\right|+\\left|F_{t}\\right|\\right) / 2}$\n",
        "\n",
        "* Symmetric mean absolute percentage error (SMAPE or sMAPE) is an accuracy measure based on percentage (or relative) errors.\n",
        "\n",
        "* At is the actual value and Ft is the forecast value\n",
        "\n",
        "* The absolute‚ÄÖdifference between At and Ft is divided by half the sum of absolute values of the actual value At and the forecast value Ft. The value of this calculation is summed for every fitted point t and divided again by the number of fitted points n.\n",
        "\n",
        "* Armstrong's original definition is as follows:\n",
        "\n",
        "$\\mathrm{SMAPE (old)}=\\frac{1}{n} \\sum_{t=1}^{n} \\frac{\\left|F_{t}-A_{t}\\right|}{\\left(A_{t}+F_{t}\\right) / 2}$\n",
        "\n",
        "* The problem is that it can be negative (if ${\\displaystyle A_{t}+F_{t}<0}$) or even undefined (if ${\\displaystyle A_{t}+F_{t}=0}$). Therefore the currently accepted version of SMAPE assumes the absolute values in the denominator.\n",
        "\n",
        "* In contrast to the mean‚ÄÖabsolute‚ÄÖpercentage‚ÄÖerror, SMAPE has both a lower bound and an upper bound. Indeed, the formula above provides a result between 0% and 200%. However a percentage error between 0% and 100% is much easier to interpret. That is the reason why the formula below is often used in practice (i.e. no factor 0.5 in denominator)\n",
        "\n",
        "* One supposed problem with SMAPE is that it is not symmetric since over- and under-forecasts are not treated equally. This is illustrated by the following example by applying the second SMAPE formula:\n",
        "\n",
        "  * Over-forecasting: At = 100 and Ft = 110 give SMAPE = 4.76%\n",
        "\n",
        "  * Under-forecasting: At = 100 and Ft = 90 give SMAPE = 5.26%.\n",
        "\n",
        "* [Wiki](https://en.m.wikipedia.org/wiki/Symmetric_mean_absolute_percentage_error) & [Wiki2](https://wiki2.org/en/Symmetric_mean_absolute_percentage_error) & [other](https://www.brightworkresearch.com/the-problem-with-using-smape-for-forecast-error-measurement/)"
      ],
      "metadata": {
        "id": "woNJbBtORpMd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mean absolute scaled error (MASE)**\n",
        "\n",
        "* mean absolute scaled error (MASE) is a measure of the accuracy of forecasts.\n",
        "\n",
        "*  It is the mean absolute error of the forecast values, divided by the mean absolute error of the in-sample one-step naive forecast. It was proposed in 2005.\n",
        "\n",
        "* The mean absolute scaled error has the following desirable propertie: [Wiki](https://en.wikipedia.org/wiki/Mean_absolute_scaled_error)"
      ],
      "metadata": {
        "id": "0BjFXbE5RpMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Huber Loss (Smooth Mean Absolute Error)**\n",
        "\n",
        "* TLDR: will better find a minimum than L1, but less exposed to outliers than L2. However one has to tune the hyperparameter delta. The larger (3+), the more it is L2, the smaller (1), the more it is L1.\n",
        "\n",
        "* The Huber loss **combines the best properties of MSE and MAE** (Mean Absolute Error). It is quadratic for smaller errors and is linear otherwise (and similarly for its gradient). It is identified by its delta parameter.\n",
        "\n",
        "* It's **less sensitive to outliers** in data than the squared error loss. It‚Äôs **also differentiable at 0**. It‚Äôs basically absolute error, which becomes quadratic when error is small.  How small that error has to be to make it quadratic depends on a hyperparameter ùõø.\n",
        "\n",
        "* Once differentiable.\n",
        "\n",
        "$L_{\\delta}(y, f(x))=\\left\\{\\begin{array}{ll}\n",
        "\\frac{1}{2}(y-f(x))^{2} & \\text { for }|y-f(x)| \\leq \\delta \\\\\n",
        "\\delta|y-f(x)|-\\frac{1}{2} \\delta^{2} & \\text { otherwise }\n",
        "\\end{array}\\right.$\n",
        "\n",
        "* **Huber loss approaches MSE when ùõø ~ 0 and MAE when ùõø ~ ‚àû**\n",
        "\n",
        "* The choice of delta is critical because it determines what you‚Äôre willing to consider as an outlier. Residuals larger than delta are minimized with L1 (which is less sensitive to large outliers), while residuals smaller than delta are minimized ‚Äúappropriately‚Äù with L2.\n",
        "\n",
        "* One big problem with using MAE for training of neural nets is its constantly large gradient, which can lead to missing minima at the end of training using gradient descent. For MSE, gradient decreases as the loss gets close to its minima, making it more precise.\n",
        "Huber loss can be really helpful in such cases, as it curves around the minima which decreases the gradient. And it‚Äôs more robust to outliers than MSE. Therefore, **it combines good properties from both MSE and MAE**.\n",
        "\n",
        "* However, the problem with Huber loss is that we might need to train hyperparameter delta which is an iterative process.\n",
        "\n",
        "* [Wiki](https://en.m.wikipedia.org/wiki/Huber_loss) * [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/losses/Huber)\n",
        "\n",
        "* https://towardsdatascience.com/understanding-the-3-most-common-loss-functions-for-machine-learning-regression-23e0ef3e14d3\n",
        "\n",
        "* The biggest problem with using MAE to train neural networks is the constant large gradient, which may cause the minimum point to be missed when the gradient descent is about to end. For MSE, the gradient will decrease as the loss decreases, making the result more accurate.\n",
        "\n",
        "* In this case, Huber loss is very useful. It will fall near the minimum value due to the decreasing gradient. It is more robust to outliers than MSE. Therefore, Huber loss combines the advantages of MSE and MAE. However, the problem with Huber loss is that we may need to constantly adjust the hyperparameters\n",
        "\n",
        "* https://www.programmersought.com/article/86974383768/\n",
        "\n",
        "* When you compare this statement with the benefits and disbenefits of both the MAE and the MSE, you‚Äôll gain some insights about how to adapt this delta parameter:\n",
        "\n",
        "* **If your dataset contains large outliers**, it‚Äôs likely that your model will not be able to predict them correctly at once. In fact, it might take quite some time for it to recognize these, if it can do so at all. This results in large errors between predicted values and actual targets, because they‚Äôre outliers. Since MSE squares errors, large outliers will distort your loss value significantly. If outliers are present, you likely don‚Äôt want to use MSE. Huber loss will still be useful, but you‚Äôll have to use small values for ùõø.\n",
        "\n",
        "* If it does not contain many outliers, it‚Äôs likely that it will generate quite accurate predictions from the start ‚Äì or at least, from some epochs after starting the training process. In this case, you may observe that the errors are very small overall. Then, one can argue, it may be worthwhile to let the largest small errors contribute more significantly to the error than the smaller ones. In this case, MSE is actually useful; hence, with Huber loss, you‚Äôll likely want to use quite large values for ùõø.\n",
        "\n",
        "* If you don‚Äôt know, you can always start somewhere in between ‚Äì for example, in the plot above, ùõø = 1 represented MAE quite accurately, while ùõø = 3 tends to go towards MSE already. What if you used ùõø = 1.5 instead? You may benefit from both worlds.\n",
        "\n",
        "https://www.machinecurve.com/index.php/2019/10/12/using-huber-loss-in-keras/\n",
        "\n",
        "* For target = 0, the loss increases when the error increases. However, the speed with which it increases depends on this ùõø value. In fact, Grover (2019) writes about this as follows: Huber loss approaches MAE when ùõø ~ 0 and MSE when ùõø ~ ‚àû (large numbers.)\n",
        "\n",
        "![xx](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Huber_loss.svg/320px-Huber_loss.svg.png)\n",
        "\n",
        "*Huber loss (green,\n",
        "Œ¥\n",
        "=\n",
        "1) and squared error loss (blue) as a function of\n",
        "y\n",
        "‚àí\n",
        "f\n",
        "(\n",
        "x\n",
        ")*\n",
        "\n",
        "![huber](https://raw.githubusercontent.com/deltorobarba/repo/master/huberloss.jpg)"
      ],
      "metadata": {
        "id": "TgFnTKWvRpMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log-Cosh Loss**\n",
        "\n",
        "* TLDR: Similar to MAE, will not be affected by outliers. Log-Cosh has all the points of Huber loss, and no need to set hyperparameters. Compared with Huber, Log-Cosh derivation is more complicated, requires more computation, and is not used much in deep learning.\n",
        "\n",
        "* * Log-cosh is another function used in regression tasks that‚Äôs smoother than L2 (is smoothed towards large errors (presumably caused by outliers) so that the final error score isn‚Äôt impacted thoroughly.)\n",
        "* Log-cosh is the logarithm of the hyperbolic cosine of the prediction error. ‚ÄúLog-cosh is the logarithm of the hyperbolic cosine of the prediction error.‚Äù (Grover, 2019). Oops, that‚Äôs not intuitive but nevertheless quite important ‚Äì this is the maths behind Logcosh loss:\n",
        "\n",
        "> $\\log \\cosh (t)=\\sum_{p \\in P} \\log (\\cosh (p-t))$\n",
        "\n",
        "* Similar to Huber Loss, but twice differentiable everywhere\n",
        "* [Wiki Hyperbolic Functions](https://en.m.wikipedia.org/wiki/Hyperbolic_functions), [TF Class](https://www.tensorflow.org/api_docs/python/tf/keras/losses/LogCosh), [Machinecurve](https://www.machinecurve.com/index.php/2019/10/23/how-to-use-logcosh-with-keras/)\n",
        "\n",
        "* However, Log-Cosh is second-order differentiable everywhere, which is still very useful in some machine learning models. For example, XGBoost uses Newton's method to find the best advantage. Newton's method requires solving the second derivative (Hessian). Therefore, for machine learning frameworks such as XGBoost, the second order of the loss function is differentiable. But the Log-cosh loss is not perfect, and there are still some problems. For example, if the error is large, the first step and Hessian will become fixed, which leads to the lack of split points in XGBoost.\n",
        "\n",
        "https://www.programmersought.com/article/86974383768/\n",
        "\n",
        "![logcosh](https://raw.githubusercontent.com/deltorobarba/repo/master/logcosh.jpeg)"
      ],
      "metadata": {
        "id": "BS-jajamRpMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quantile Loss (Pinball Loss)**\n",
        "\n",
        "* TLDR: for Heteroskedastizit√§t, i.e. for risk management when variance changes. Quantile Loss, you can set different quantiles to control the proportion of overestimation and underestimation in loss.\n",
        "\n",
        "* estimates conditional ‚Äúquantile‚Äù of a response variable given certain values of predictor variables\n",
        "* is an extension of MAE (**when quantile is 50th percentile, it‚Äôs MAE**)\n",
        "* Im Gegensatz zur Kleinste-Quadrate-Sch√§tzung, die den Erwartungswert der Zielgr√∂√üe sch√§tzt, ist die Quantilsregression dazu geeignet, ihre Quantile zu sch√§tzen.\n",
        "* Fitting models for many percentiles, you can estimate the entire conditional distribution. Often, the answers to important questions are found by modeling percentiles in the tails of the distribution. For that reason **quantile regression provides critical insights in financial risk management & fraud detection**.\n",
        "* [Wikipedia](https://de.m.wikipedia.org/wiki/Quantilsregression), [TF Class](https://www.tensorflow.org/addons/api_docs/python/tfa/losses/PinballLoss) & [TF Function](https://www.tensorflow.org/addons/api_docs/python/tfa/losses/pinball_loss)\n",
        "\n",
        "* project where predictions were subject to high uncertainty. The client required for their decision to be driven by both the predicted machine learning output and a measure of the potential prediction error. The quantile regression loss function solves this and similar problems by replacing a single value prediction by prediction intervals.\n",
        "\n",
        "* The quantile regression loss function is applied to predict quantiles. A quantile is the value below which a fraction of observations in a group falls. For example, a prediction for quantile 0.9 should over-predict 90% of the times.\n",
        "\n",
        "* For q equal to 0.5, under-prediction and over-prediction will be penalized by the same factor, and the median is obtained. The larger the value of q, the more over-predictions are penalized compared to under-predictions. For q equal to 0.75, over-predictions will be penalized by a factor of 0.75, and under-predictions by a factor of 0.25. The model will then try to avoid over-predictions approximately three times as hard as under-predictions, and the 0.75 quantile will be obtained.\n",
        "\n",
        "* The usual regression algorithm is to fit the expected or median training data, and the quantile loss function can be used to fit different quantiles of training data by giving different quantiles.\n",
        "\n",
        "![sdd](https://raw.githubusercontent.com/deltorobarba/repo/master/quantileloss.jpg)\n",
        "\n",
        "* Set different quantiles to fit different straight lines: This function is a piecewise functio., Œ≥ is the quantile coefficient. y is the true value, f(x) is the predicted value. According to the size of the predicted value and the true value, there are two cases to consider.\n",
        "\n",
        "* y> f(x) For overestimation, the predicted value is greater than the true value;\n",
        "\n",
        "* y< f(x) to underestimate, the predicted value is smaller than the real value.\n",
        "\n",
        "* Use different pass coefficients to control the weight of overestimation and underestimation in the entire loss value.\n",
        "\n",
        "* Especially when Œ≥=0.5 When the quantile loss degenerates into the mean absolute error MAE, **MAE can also be regarded as a special case of quantile loss-median loss**. The picture below is taken with different median points [0.25,0.5,0.7] Obtaining different quantile loss function curves can also be seen as MAE at 0.5.\n",
        "\n",
        "![fgfgf](https://raw.githubusercontent.com/deltorobarba/repo/master/quantileloss2.jpg)\n",
        "\n",
        "![xx](https://upload.wikimedia.org/wikipedia/commons/thumb/b/b7/Pinball_Loss_Function.svg/320px-Pinball_Loss_Function.svg.png)\n",
        "\n",
        "*Pinball-Verlustfunktion mit\n",
        "œÑ\n",
        "=0,9. F√ºr\n",
        "Œµ\n",
        "<\n",
        "0 betr√§gt der Fehler\n",
        "‚àí\n",
        "0\n",
        ",\n",
        "1\n",
        "Œµ, f√ºr\n",
        "Œµ\n",
        "‚â•\n",
        "0 betr√§gt er\n",
        "0\n",
        ",\n",
        "9\n",
        "Œµ.*\n",
        "\n",
        "* https://www.evergreeninnovations.co/blog-quantile-loss-function-for-machine-learning/"
      ],
      "metadata": {
        "id": "v-8rQF9PRpMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Poisson Loss**\n",
        "\n",
        "* https://towardsdatascience.com/the-poisson-distribution-103abfddc312\n",
        "\n",
        "* https://towardsdatascience.com/the-poisson-distribution-and-poisson-process-explained-4e2cb17d459\n"
      ],
      "metadata": {
        "id": "WYKjQ9BdRpMf"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1flpzoQFTVa"
      },
      "source": [
        "###### *Stochastic Analysis*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![geometry](https://raw.githubusercontent.com/deltorobarba/repo/master/sciences_1605.png)\n",
        "\n",
        "https://www.researchgate.net/figure/A-flowchart-showing-different-types-of-stochastic-processes-Processes-lower-in-the-chart_fig2_330251417\n",
        "\n",
        "http://home.ubalt.edu/ntsbarsh/simulation/sim.htm"
      ],
      "metadata": {
        "id": "m_CrbI1s1u5d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stochastic Analysis**\n",
        "\n",
        "* [Stochastic calculus](https://en.m.wikipedia.org/wiki/Stochastic_calculus) bzw. [Stochastische Analysis](https://de.m.wikipedia.org/wiki/Stochastische_Analysis) is a branch of mathematics that operates on stochastic processes. It allows a consistent theory of integration to be defined for integrals of stochastic processes with respect to stochastic processes. This field is created and started by the Japanese mathematician Kiyoshi It√¥ during World War 2.\n",
        "\n",
        "* [Stochastische_Integration](https://de.m.wikipedia.org/wiki/Stochastische_Integration): Es sind stochastische Prozesse mit unendlicher Variation, insbesondere der Wiener-Prozess, als Integratoren zugelassen.\n",
        "\n",
        "* [Stochastischer Prozess](https://de.m.wikipedia.org/wiki/Stochastischer_Prozess): (auch Zufallsprozess) zeitlich geordnete, zuf√§llige Vorg√§nge. Theorie der stochastischen Prozesse ist Erweiterung der Wahrscheinlichkeitstheorie dar und bildet Grundlage f√ºr stochastische Analysis.\n",
        "\n",
        "* > Stochastic: Statistik + Probability Theory (incl stochastic / random processes)\n",
        "\n",
        "* Bei einem Sparguthaben entspr√§che dies dem **exponentiellen Wachstum** durch Zinseszins. Bei Aktien wird dieses Wachstumsgesetz hingegen **in der Realit√§t offenbar durch eine komplizierte Zufallsbewegung √ºberlagert**.\n",
        "\n",
        "* Bei zuf√§lligen St√∂rungen, die sich aus vielen kleinen Einzel√§nderungen zusammensetzen, **wird von einer Normalverteilung als einfachstem Modell ausgegangen**.\n",
        "\n",
        "* Au√üerdem zeigt sich, dass die Varianz der St√∂rungen proportional zum betrachteten Zeitraum $\\Delta t$ ist. Der Wiener-Prozess $W_t$ besitzt alle diese gew√ºnschten Eigenschaften, eignet sich also als ein Modell f√ºr die zeitliche Entwicklung der Zufallskomponente des Aktienkurses.\n"
      ],
      "metadata": {
        "id": "DC-KHFg7J17I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO0iE2bRTLxY"
      },
      "source": [
        "**Stochastic Differential Equation ( ‚Üí  Black Scholes, Spontaneous Symmetry Breaking)**\n",
        "\n",
        "* Eine [stochastischen Differentialgleichung](https://de.wikipedia.org/wiki/Stochastische_Differentialgleichung) ist eine Verallgemeinerung des Begriffs der gew√∂hnlichen Differentialgleichung auf stochastische Prozesse.\n",
        "\n",
        "> Stochastische Differentialgleichungen werden in zahlreichen Anwendungen eingesetzt, **um zeitabh√§ngige Vorg√§nge zu modellieren**, die neben deterministischen Einfl√ºssen zus√§tzlich **stochastischen St√∂rfaktoren (Rauschen)** ausgesetzt sind.\n",
        "\n",
        "* Die formale Theorie der stochastischen Differentialgleichungen wurde erst in den 1940er Jahren durch den japanischen Mathematiker It≈ç Kiyoshi formuliert.\n",
        "\n",
        "* Gemeinsam mit der **stochastischen Integration** begr√ºndet die Theorie der **stochastischen Differentialgleichungen** die **stochastische Analysis**.\n",
        "\n",
        "* **Objective**: Genau wie bei deterministischen Funktionen m√∂chte man auch bei stochastischen Prozessen den Zusammenhang zwischen dem Wert der Funktion und ihrer momentanen √Ñnderung (ihrer Ableitung) in einer Gleichung formulieren.\n",
        "\n",
        "* **Challenge**: Was im einen Fall zu einer gew√∂hnlichen Differentialgleichung f√ºhrt, ist im anderen Fall problematisch, da viele stochastische Prozesse, wie beispielsweise **der Wiener-Prozess, nirgends differenzierbar sind**.\n",
        "\n",
        "* Loesung ist wie bei gewohnlichen Differentialgleichungen plus einen stochastischen Term\n",
        "\n",
        "*Beim Typus der stochastischen Differentialgleichungen treten in der Gleichung stochastische Prozesse auf. Eigentlich sind stochastische Differentialgleichungen keine Differentialgleichungen [im obigen Sinne](https://de.m.wikipedia.org/wiki/Differentialgleichung#Weitere_Typen), sondern lediglich gewisse Differentialrelationen, welche als Differentialgleichung interpretiert werden k√∂nnen.*\n",
        "\n",
        "*Beispiele fur stochastische Differentialgleichungen*\n",
        "\n",
        "* Die SDGL f√ºr die geometrische brownsche Bewegung lautet $\\mathrm{d} S_{t}=r S_{t} \\mathrm{~d} t+\\sigma S_{t} \\mathrm{~d} W_{t} .$ Sie wird beispielsweise im Black-Scholes-Modell zur Beschreibung von Aktienkursen verwendet.\n",
        "\n",
        "* Die SDGL f√ºr einen Ornstein-Uhlenbeck-Prozess ist $\\mathrm{d} X_{t}=\\theta\\left(\\mu-X_{t}\\right) \\mathrm{d} t+\\sigma \\mathrm{d} W_{t} .$ Sie wird unter anderem im Vasicek-Modell zur finanzmathematischen Modellierung von Zinss√§tzen √ºber den Momentanzins\n",
        "verwendet.\n",
        "\n",
        "* Die SDGL f√ºr den Wurzel-Diffusionsprozess nach William Feller lautet $\\mathrm{d} X_{t}=\\kappa\\left(\\theta-X_{t}\\right) \\mathrm{d} t+\\sigma \\sqrt{X_{t}} \\mathrm{~d} W_{t}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eelei85Xp8rU"
      },
      "source": [
        "**Supersymmetric theory of stochastic dynamics & Spontaneous Symmetry breaking**\n",
        "\n",
        "* [Supersymmetric theory of stochastic dynamics](https://en.m.wikipedia.org/wiki/Supersymmetric_theory_of_stochastic_dynamics) or stochastics (STS) **is an exact theory of stochastic (partial) differential equations (SDEs)**, the class of mathematical models with the widest applicability covering, in particular, all continuous time dynamical systems, with and without noise.\n",
        "\n",
        "* https://en.m.wikipedia.org/wiki/Chaos_theory#Chaos_as_a_spontaneous_breakdown_of_topological_supersymmetry"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8chCbs1o_Iud"
      },
      "source": [
        "###### *White Noise*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ud0ShhpknOvG"
      },
      "source": [
        "\n",
        "**A white noise process has following conditions**\n",
        "\n",
        "* Mean (level) is zero (does not change over time - stationary process)\n",
        "* Variance is constant (does not change over time - stationary process)\n",
        "* Zero autocorrelation (values do not correlate with lag values)\n",
        "\n",
        "**White Noise: Independent & Identically Distributed**\n",
        "\n",
        "* Hence, in a time series is white noise if the variables are independent and identically distributed (IID) with a mean of zero.\n",
        "\n",
        "* The term 'white' refers to the way the signal power is distributed (i.e., independently) over time or among frequencies\n",
        "\n",
        "* **Necessary Condition**: Independence: variables are statistically uncorrelated = their covariance is zero. Therefore, the covariance matrix R of the components of a white noise vector w with n elements must be an n by n diagonal matrix, where each diagonal element R·µ¢·µ¢ is the variance of component w·µ¢; and the correlation matrix must be the n by n identity matrix.\n",
        "\n",
        "* **Sufficient Condition**: every variable in w has a normal distribution with zero mean and the same variance, w is said to be a Gaussian white noise vector. In that case, the joint distribution of w is a multivariate normal distribution; the independence between the variables then implies that the distribution has spherical symmetry in n-dimensional space. Therefore, any orthogonal transformation of the vector will result in a Gaussian white random vector. In particular, under most types of discrete Fourier transform, such as FFT and Hartley, the transform W of w will be a Gaussian white noise vector, too; that is, the n Fourier coefficients of w will be independent Gaussian variables with zero mean and the same variance.\n",
        "\n",
        "* A random vector (that is, a partially indeterminate process that produces vectors of real numbers) is said to be a white noise vector or white random vector if its components each have a probability distribution with zero mean and finite variance, and are statistically independent: that is, their joint probability distribution must be the product of the distributions of the individual components.\n",
        "\n",
        "* First moment has to be zero and second moment has to be finite though. (iid ) White noise is always an independent process but reverse may not be true.\n",
        "\n",
        "* The technical definition of white noise is that it has equal intensity at all frequencies. This corresponds to a delta function autocorrelation. This is only possible if there is no correlation between any sequential values. So yes, the independence is true both backwards and forwards. Note that the actual distribution is irrelevant.\n",
        "\n",
        "\n",
        "\n",
        "**Types of White Noise Processes**\n",
        "* If the variables in the series are drawn from a Gaussian distribution, the series is called Gaussian white noise\n",
        "* There are also white noise processes, like Levy etc.\n",
        "\n",
        "**Relationship to Stochastic Processes**\n",
        "* White noise is the generalized mean-square derivative of the Wiener process or Brownian motion (so Wiener is an integrated White Noise)\n",
        "\n",
        "**White noise is an important concept in time series analysis and forecasting**\n",
        "\n",
        "* **Predictability**: If your time series is white noise, then, by definition, it is random. You cannot reasonably model it and make predictions.\n",
        "* **Model Diagnostics**: The statistics and diagnostic plots can be uses on time series to check if it is white noise. The series of errors from a time series forecast model should ideally be white noise. If the series of forecast errors are not white noise, it suggests improvements could be made to the predictive model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8idRoUCpsoKR"
      },
      "source": [
        "###### *Random Walk*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdW8o7tCtbPh"
      },
      "source": [
        "**Random Walk**\n",
        "\n",
        "* Random walk is another time series model where the current observation is equal to the previous observation with a random step up or down. Known as a stochastic or random process.\n",
        "\n",
        "> y<sub>(t)</sub> = B<sub>0</sub> + B<sub>1</sub> * X<sub>(t-1)</sub> + e<sub>(t)</sub>\n",
        "\n",
        "* A random walk is different from a list of random numbers because the next value in the sequence is a modification of the previous value in the sequence.\n",
        "\n",
        "* The process used to generate the series forces dependence from one-time step to the next. This dependence provides some consistency from step-to-step rather than the large jumps that a series of independent, random numbers provides. It is this dependency that gives the process its name as a ‚Äúrandom walk‚Äù or a ‚Äúdrunkard‚Äôs walk‚Äù.\n",
        "\n",
        "> **A simple random walk is a martingale**\n",
        "\n",
        "* In higher dimensions, the set of randomly walked points has interesting geometric properties. In fact, one gets a discrete fractal, that is, a set which exhibits stochastic self-similarity on large scales.\n",
        "* Examples include the path traced by a molecule as it travels in a liquid or a gas, the search path of a foraging animal, the price of a fluctuating stock and the financial status of a gambler: all can be approximated by random walk models, even though they may not be truly random in reality\n",
        "* Random walks serve as a fundamental model for the recorded stochastic activity / stochastic processes.\n",
        "* As a more mathematical application, the value of œÄ can be approximated by the use of random walk in an agent-based modeling environment.\n",
        "\n",
        "* There are many types of time-dependent processes referred to as random walks - most often refers to a special category of Markov chains or Markov processes. A random walk on the integers (and the gambler's ruin problem) are examples of **Markov processes in discrete time**.\n",
        "\n",
        "* Specific cases or limits of random walks include the L√©vy flight and diffusion models such as Brownian motion. **A Wiener process (~ Brownian motion) is the integral of a white noise generalized Gaussian process**. It is not stationary, but it has stationary increments. A Wiener process is the scaling limit of random walk in dimension 1.\n",
        "\n",
        "* Random walks can take place on a variety of spaces: graphs, on the integers or real line, in the plane or higher-dimensional vector spaces, on curved surfaces or higher-dimensional Riemannian manifolds, and also on groups finite, finitely generated or Lie.\n",
        "\n",
        "* **Random Walk and Autocorrelation**\n",
        "\n",
        "  * We can calculate the correlation between each observation and the observations at previous time steps. Given the way that the random walk is constructed, we would expect a strong autocorrelation with the previous observation and a linear fall off from there with previous lag values.\n",
        "\n",
        "* **Stationarity**\n",
        "\n",
        "  * A stationary time series is one where the values are not a function of time. Given the way that the random walk is constructed and the results of reviewing the autocorrelation, we know that the observations in a random walk are dependent on time.\n",
        "  * The current observation is a random step from the previous observation. Therefore we can expect a random walk to be non-stationary. In fact, all random walk processes are non-stationary. Note that not all non-stationary time series are random walks.\n",
        "  * Additionally, a non-stationary time series does not have a consistent mean and/or variance over time. A review of the random walk line plot might suggest this to be the case. We can confirm this using a statistical significance test, specifically the Augmented Dickey-Fuller test.\n",
        "\n",
        "**IID**\n",
        "\n",
        "  * This model assumes that in each period the variable takes a random step away from its previous value, and the steps are independently and identically distributed in size (‚Äúi.i.d.‚Äù).\n",
        "\n",
        "  * This is equivalent to saying that the first difference of the variable is a series to which the mean model should be applied. So, if you begin with a time series that wanders all over the map, but you find that its first difference looks like it is an i.i.d. sequence, then a random walk model is a potentially good candidate.\n",
        "\n",
        "* **Prediction**\n",
        "\n",
        "  * A random walk is unpredictable; it cannot reasonably be predicted. Given the way that the random walk is constructed, we can expect that the best prediction we could make would be to use the observation at the previous time step as what will happen in the next time step. Simply because we know that the next time step will be a function of the prior time step.\n",
        "  * This is often called the naive forecast, or a persistence model. We can implement this in Python by first splitting the dataset into train and test sets, then using the persistence model to predict the outcome using a rolling forecast method. Once all predictions are collected for the test set, the mean squared error is calculated.\n",
        "\n",
        "* **Drift**\n",
        "\n",
        "  * A random walk model is said to have ‚Äúdrift‚Äù or ‚Äúno drift‚Äù according to whether the distribution of step sizes has a non-zero mean or a zero mean. At period n, the k-step-ahead forecast that the random walk model without drift gives for the variable Y is\n",
        "\n",
        "  > $\\hat{Y}_{n+k}=Y_{n}$\n",
        "\n",
        "  * In others words, it predicts that all future values will equal the last observed value. This doesn‚Äôt really mean you expect them to all be the same, but just that you think they are equally likely to be higher or lower, and you are staying on the fence as far as point predictions are concerned. If you extrapolate forecasts from the random walk model into the distant future, they will go off on a horizontal line, just like the forecasts of the mean model. So, qualitatively the long-term point forecasts of the random walk model look similar to those of the mean model, except that they are always ‚Äúre-anchored‚Äù on the last observed value rather than the mean.of the historical data.\n",
        "\n",
        "  * For the random-walk-with-drift model, the k-step-ahead forecast from period n is:\n",
        "\n",
        "  > $\\hat{\\mathrm{Y}}_{\\mathrm{n}+\\mathrm{k}}=\\mathrm{Y}_{\\mathrm{n}}+\\mathrm{k} \\hat{\\mathrm{d}}$\n",
        "\n",
        "  * where dÀÜ is the estimated drift, i.e., the average increase from one period to the next. So, the long-term forecasts from the random-walk-with-drift model look like a trend line with slope dÀÜ , but it is always re-anchored on the last observed value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUbYRNP_zXe4"
      },
      "source": [
        "###### *Wiener Process (Brownian Motion)*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldqy2UtMpa8P"
      },
      "source": [
        "**Wiener Process (Brownian Motion)**\n",
        "\n",
        "* Video: Physics of Randomness: https://youtu.be/5jBVYvHeG2c\n",
        "\n",
        "* Brownian Motion: Flower particles move randomly because they are hit by particles that move. And particles move faster with more heat.\n",
        "\n",
        "* Same in astrophysics with stars under the gravitational influence of smaller stars, big stars move a bit randomly\n",
        "\n",
        "* Same with stock market where the price is influenced by many factors all the time (and hence the price moves randomly up and down)\n",
        "\n",
        "**The Wiener process is a real valued continuous-time (continuous state-space) stochastic process**\n",
        "\n",
        "* W<sub>0</sub> = 0 (P-almost certain)\n",
        "* The Wiener process has (stochastically) independent increments.\n",
        "* The increases are therefore stationary and normally distributed with the expected value zero and the variance t - s.\n",
        "* The individual paths are (P-) almost certainly continuous.\n",
        "\n",
        "**Applications**\n",
        "\n",
        "* In physics it is used to study Brownian motion, the diffusion of minute particles suspended in fluid, and other types of diffusion via the Fokker‚ÄìPlanck and Langevin equations.\n",
        "* It also forms the basis for the rigorous path integral formulation of quantum mechanics (by the Feynman‚ÄìKac formula, a solution to the Schr√∂dinger equation can be represented in terms of the Wiener process) and the study of eternal inflation in physical cosmology.\n",
        "* It is also prominent in the mathematical theory of finance, in particular the Black‚ÄìScholes option pricing model.\n",
        "\n",
        "**Properties of a Wiener Process**\n",
        "\n",
        "1. The Wiener process belongs to the family of **Markov processes** and there specifically to the class of **Levy processes**. It also fulfills the strong markov property. It is one of the best known L√©vy processes (**c√†dl√†g** stochastic processes with stationary independent increments).\n",
        "2. The Wiener Process is a **special Gaussian process** with an expected value function E(W<sub>t</sub>)  = 0 and and the covariance function Cov (W<sub>s</sub>, W<sub>t</sub>) = min (s,t)\n",
        "3. The Wiener process is a (continuous time) **martingale** (L√©vy characterisation: the Wiener process is an almost surely continuous martingale with W0 = 0 and quadratic variation [Wt, Wt] = t, which means that Wt2 ‚àí t is also a martingale).\n",
        "4. The Wiener process is a **Levy process** with steady paths and constant expectation 0.\n",
        "\n",
        "*Another characterisation is that the Wiener process has a spectral representation as a sine series whose coefficients are independent N(0, 1) random variables. This representation can be obtained using the Karhunen‚ÄìLo√®ve theorem.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9PQvsR1bKfq"
      },
      "source": [
        "**Wiener process as a limit of random walk (& Differences between Wiener Process & Random Walk)**\n",
        "\n",
        "* https://www.quora.com/What-is-an-intuitive-explanation-of-a-Wiener-process?top_ans=3955819\n",
        "\n",
        "* A Wiener process (~ Brownian motion) is the **integral of a white noise generalized Gaussian process**. It is not stationary, but it has stationary increments.\n",
        "\n",
        "* Let X<sub>1</sub>, X<sub>2</sub>, X<sub>n</sub> be a sequence of independent and identically distributed (i.i.d.) random variables with mean 0 and variance 1.  The central limit theorem asserts that W<sup>(n)</sup> (1) converges in distribution to a standard Gaussian random variable W(1) as n ‚Üí ‚àû.\n",
        "\n",
        "* [Donsker's theorem](https://en.m.wikipedia.org/wiki/Donsker%27s_theorem) asserts that as n ‚Üí ‚àû , W<sub>n</sub> approaches a Wiener process, which explains the ubiquity of Brownian motion. **Donsker's invariance principle** states that: As random variables taking values in the Skorokhod space D [0,1], the random function W<sup>(n)</sup> converges in distribution to a standard Brownian motion W := (W(t))<sub>t ‚àà [0,1]</sub> as n ‚Üí ‚àû.\n",
        "\n",
        "![Donsker's Invariance Principle](https://upload.wikimedia.org/wikipedia/commons/8/8c/Donskers_invariance_principle.gif)\n",
        "\n",
        "*Donsker's invariance principle for simple random walk on Z*\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/deltorobarba/repo/master/wiener.jpg\" alt=\"wiener\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKFiwhd7X_5I"
      },
      "source": [
        "**Differences to other stochastic processes**\n",
        "\n",
        "**Random Walk**\n",
        "\n",
        "\n",
        "* **A Wiener process is the [scaling limit](https://en.m.wikipedia.org/wiki/Scaling_limit) of random walk in dimension 1**. The **convergence of a random walk toward the Wiener process is controlled by the central limit theorem**, and by **Donsker's theorem**. The **Green's function** of the diffusion equation that controls the Wiener process, suggests that, **after a large number of steps, the random walk converges toward a Wiener process**.\n",
        "\n",
        "* A random walk is a discrete fractal (a function with integer dimensions; 1, 2, ...), but a **Wiener process trajectory is a true fractal**, and there is a connection between the two (a Wiener process walk is a fractal of **Hausdorff dimension** 2).\n",
        "\n",
        "* Unlike the random walk, a **Wiener Process is scale invariant**. A Wiener process enjoys many symmetries random walk does not. For example, a **Wiener process walk is invariant to rotations, but the random walk is not**, since the underlying grid is not. This means that in many cases, problems on a random walk are easier to solve by translating them to a Wiener process, solving the problem there, and then translating back.\n",
        "\n",
        "**(Gaussian) White Noise**\n",
        "\n",
        "* The Wiener process is used to represent the integral (from time zero to time t) of a zero mean, unit variance, delta correlated **<u>Gaussian</u> white noise process**\n",
        "\n",
        "**Brownian Motion**\n",
        "\n",
        "* **\"Brownian motion\" is a phenomenon that can be modeled with a Wiener Process**, because a Wiener process is a stochastic process with similar behavior to Brownian motion, the physical phenomenon of a minute particle diffusing in a fluid.\n",
        "\n",
        "* The Brownian motion process (and the Poisson process in one dimension) are both examples of **Markov processes in continuous time**\n",
        "\n",
        "* It≈ç also paved the way for the Wiener process from physics to other sciences: the **stochastic differential equations** he set up made it possible to adapt the Brownian motion to more statistical problems.\n",
        "\n",
        "* The **geometric Brownian motion** derived from a stochastic differential equation solves the problem that the **Wiener process, regardless of its starting value, almost certainly reaches negative values over time, which is impossible for stocks**. Since the development of the famous **Black-Scholes model**, the geometric Brownian movement has been the standard.\n",
        "\n",
        "**Ornstein-Uhlenbeck-Process**\n",
        "\n",
        "* The problem raised by the **[non-rectifiable paths](https://en.m.wikipedia.org/wiki/Arc_length)** of the Wiener process in the modeling of Brownian paths leads to the Ornstein-Uhlenbeck process and also makes the need for a theory of stochastic integration and differentiation clear\n",
        "* here it is not the motion but the speed of the particle as one that is not rectifiable process derived from the Wiener process, from which one obtains rectifiable particle paths through integration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0K1gPOoznzE"
      },
      "source": [
        "###### *Gaussian Process*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZoS5J618HxN"
      },
      "source": [
        "* A Gaussian process is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i.e. **every finite linear combination of them is normally distributed**.\n",
        "\n",
        "* The distribution of a Gaussian process is the joint distribution of all those (infinitely many) random variables, and as such, it is a distribution over functions with a continuous domain, e.g. time or space.\n",
        "\n",
        "* Gaussian Processes are a class of stationary, zero-mean stochastic processes which are completely dependent on their autocovariance functions. This class of models can be used for both regression and classification tasks.\n",
        "\n",
        "* Gaussian Processes provide estimates about uncertainty, for example giving an estimate of how sure an algorithm is that an item belongs to a class or not.\n",
        "\n",
        "* In order to deal with situations which embed a certain degree of uncertainty is typically made use of probability distributions.\n",
        "\n",
        "* Gaussian processes can allow us to describe probability distributions of which we can later update the distribution using Bayes Rule once we gather new training data.\n",
        "\n",
        "* **Relation to other Stochastic Processes**\n",
        "\n",
        "  * A **Wiener process (~ Brownian motion)** is the integral of a white noise generalized Gaussian process. It is not stationary, but it has stationary increments.\n",
        "\n",
        "  * The **fractional Brownian motion** is a Gaussian process whose covariance function is a generalisation of that of the Wiener process.\n",
        "\n",
        "  * The **Ornstein‚ÄìUhlenbeck** process is a stationary Gaussian process.\n",
        "\n",
        "  * The **Brownian bridge** is (like the Ornstein‚ÄìUhlenbeck process) an example of a Gaussian process whose increments are not independent.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVOw3me6qbku"
      },
      "source": [
        "###### *Brownian Bridge*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEr4Ub47xgN1"
      },
      "source": [
        "**Brownian Bridge**\n",
        "\n",
        "* A Brownian bridge is a **continuous Gaussian process** with X<sub>0</sub> = X<sub>1</sub> = 0, and with mean and covariance functions given in (c) and (d), respectively.\n",
        "\n",
        "* The **Brownian bridge is (like the Ornstein‚ÄìUhlenbeck process)** an example of a Gaussian process **whose increments are not independent**.\n",
        "\n",
        "* There are several ways of constructing a Brownian bridge from a standard Brownian motion [Source](https://www.randomservices.org/random/brown/Bridge.html)\n",
        "\n",
        "* **Applications: Path Simulation for Stock Shares**: The simple Monte Carlo method with Euler method supplemented by the Brownian bridge correction for the possibility of falling below or exceeding the barriers between discretization times.\n",
        "\n",
        "  * By merely discreetly viewing (simulating) the (log) share price, those paths can also lead to a positive final payment in which the share price between the selected times k delta t has exceeded the lower barrier or exceeded the upper barrier without this is noticed in the discretized model.\n",
        "\n",
        "  * To calculate the probability of such an unnoticed barrier violation, Brownian Bridge is used (with the help of the independence and stationarity of its growth).\n",
        "\n",
        "  * With the help of the statements about the Brown Bridge, one can formally. Specify the Monte Carlo algorithm that can be used to evaluate double barrier options without having to discretize the price path.\n",
        "\n",
        "* **Application: Bond Prices**\n",
        "\n",
        "  * Computation of bond prices in a structural default model with jumps with an unbiased Monte-Carlo simulation.\n",
        "\n",
        "  * The algorithm requires the evaluation of integrals with the density of the first-passage time of a Brownian bridge as the integrand. (Metwally and Atiya (2002) suggest an approximation of these integrals.)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Ornstein-Uhlenbeck Process*"
      ],
      "metadata": {
        "id": "DAdF2iW5biD_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0CRhOchiHXb"
      },
      "source": [
        "**Ornstein-Uhlenbeck Process**\n",
        "\n",
        "> Simulating a stochastic differential equation\n",
        "\n",
        "* the Ornstein‚ÄìUhlenbeck process is a **stochastic process** with applications in financial mathematics and the physical sciences.\n",
        "\n",
        "* Its original application in physics was as a model for the **<u>velocity</u> of a massive Brownian particle under the influence of <u>friction</u>**. It is named after Leonard Ornstein and George Eugene Uhlenbeck.\n",
        "\n",
        "* The Ornstein‚ÄìUhlenbeck process is a **stationary Gauss‚ÄìMarkov process**, which means that it is a **Gaussian process, a Markov process, and is temporally homogeneous**. In fact, it is the only nontrivial process that satisfies these three conditions, up to allowing linear transformations of the space and time variables.\n",
        "\n",
        "* Over time, the process tends to **drift towards its mean function**: such a process is called **mean-reverting**.\n",
        "\n",
        "* The process can be considered to be a **modification of the random walk in continuous time, or Wiener process**, in which the properties of the process have been changed so that there is a tendency of the walk to move back towards a central location, with a greater attraction when the process is further away from the center.\n",
        "\n",
        "* The Ornstein‚ÄìUhlenbeck process can also be considered as the **continuous-time analogue of the discrete-time AR(1) process**.\n",
        "\n",
        "* The Ornstein‚ÄìUhlenbeck process can be interpreted as a **scaling limit of a discrete process**, in the same way that Brownian motion is a scaling limit of random walks.\n",
        "\n",
        "* Generalization: It is possible to extend Ornstein‚ÄìUhlenbeck processes to processes where the background driving process is a L√©vy process (instead of a simple Brownian motion).\n",
        "\n",
        "* In addition, in finance, stochastic processes are used where the volatility increases for larger values of C.\n",
        "\n",
        "* The Ornstein‚ÄìUhlenbeck process (just like the Brownian Bridge) a is an example of a **Gaussian process whose increments are not independent**. Look for stock returns devoid of explanatory factors, and analyze the corresponding residuals as stochastic processes. (e.g. mean reverting?). Can residuals be fitted to (increments of) OU processes or other MR processes? If so, what is the typical correlation time-scale? Mean reversion days: how long does it take to converge (e.g. model distribution of days).\n",
        "\n",
        "**In Financial Mathematics**\n",
        "\n",
        "* The Ornstein‚ÄìUhlenbeck process is one of several approaches used to model (with modifications) interest rates, currency exchange rates, and commodity prices stochastically.\n",
        "\n",
        "* The parameter Œº (mu) represents the equilibrium or mean value supported by fundamentals; œÉ (signa) the degree of volatility around it caused by shocks, and Œ∏ (theta) the rate by which these shocks dissipate and the variable reverts towards the mean.\n",
        "\n",
        "* One application of the process is a trading strategy known as pairs trade.\n",
        "\n",
        "* Stationary and mean-reverting around mean=10 (red dotted line)\n",
        "* **In financial engineering: how long does it take in average to converge? mean-reversion is an investment opportunity!**\n",
        "* Now, we are going to take a look at the time evolution of the distribution of the process. To do this, we will simulate many independent realizations of the same process in a vectorized way. We define a vector X that will contain all realizations of the process at a given time (that is, we do not keep all realizations at all times in memory). This vector will be overwritten at every time step. We will show the estimated distribution (histograms) at several points in time:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Jump diffusion*"
      ],
      "metadata": {
        "id": "H6kSAH20bmvm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJqrw3_Nqev5"
      },
      "source": [
        "**Jump diffusion**\n",
        "\n",
        "* [Jump diffusion](https://en.m.wikipedia.org/wiki/Jump_diffusion) is a stochastic process that involves jumps and diffusion.\n",
        "\n",
        "* It has important applications in magnetic reconnection, coronal mass ejections, condensed matter physics, option pricing, and pattern theory and computational vision.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *L√©vy Process*"
      ],
      "metadata": {
        "id": "s9HF-07Hbona"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTQP6Jd68WsL"
      },
      "source": [
        "**L√©vy Process**\n",
        "\n",
        "* A L√©vy process is a stochastic process with **[independent, stationary increments](https://de.m.wikipedia.org/wiki/Prozess_mit_unabh√§ngigen_Zuw√§chsen)** (= the course of the future of the process is independent of the past): it represents the motion of a point whose successive displacements are random and independent, and statistically identical over different time intervals of the same length.\n",
        "\n",
        "* A L√©vy process may thus be viewed as the **continuous-time analog of a random walk**.\n",
        "\n",
        "* The most well known **examples of L√©vy processes are Wiener process (~ Brownian motion), and Poisson process**. Aside from Brownian motion with drift, all other proper (that is, not deterministic) L√©vy processes have discontinuous paths."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Bernoulli Process*"
      ],
      "metadata": {
        "id": "Frb1ShYDbqfh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaAvA4JovM_-"
      },
      "source": [
        "**Bernoulli Process**\n",
        "\n",
        "* The outcomes of a Bernoulli process will follow a [Binomial distribution](https://en.m.wikipedia.org/wiki/Binomial_distribution).\n",
        "\n",
        "* https://machinelearningmastery.com/discrete-probability-distributions-for-machine-learning/\n",
        "\n",
        "* A Bernoulli process is a finite or infinite sequence of binary random variables, so it is a discrete-time stochastic process that takes only two values, canonically 0 and 1.\n",
        "\n",
        "* The component Bernoulli variables X<sub>i</sub> are [identically distributed and independent](https://en.m.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables). Prosaically, a Bernoulli process is a repeated coin flipping, possibly with an unfair coin (but with consistent unfairness).\n",
        "\n",
        "* Every variable X<sub>i</sub> in the sequence is associated with a Bernoulli trial or experiment. They all have the same Bernoulli distribution. Much of what can be said about the Bernoulli process can also be generalized to more than two outcomes (such as the process for a six-sided dice); this generalization is known as the **Bernoulli scheme**.\n",
        "\n",
        "* The problem of determining the process, given only a limited sample of Bernoulli trials, may be called the problem of checking whether a coin is fair."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### *Poisson (Point) Process*"
      ],
      "metadata": {
        "id": "QyRDpo40btSe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzPTaHcB54U"
      },
      "source": [
        "**Poisson (Point) Process**\n",
        "\n",
        "* Poisson point process is a type of random mathematical object that consists of points randomly located on a mathematical space\n",
        "\n",
        "* Its name derives from the fact that if a collection of random points in some space forms a Poisson process, then the number of points in a region of finite size is a random variable with a Poisson distribution.\n",
        "\n",
        "* The process was discovered independently and repeatedly in several settings, including experiments on radioactive decay, telephone call arrivals and insurance mathematics. The Poisson point process is often defined on the real line, where it can be considered as a stochastic process.\n",
        "\n",
        "* On the real line, the Poisson process is a type of **continuous-time Markov process** known as a birth-death process (with just births and zero deaths) and is called a pure or simple birth process.\n",
        "\n",
        "* In this setting, it is used, for example, in queueing theory to model random events, such as the arrival of customers at a store, phone calls at an exchange or occurrence of earthquakes, distributed in time. In the plane, the point process, also known as a spatial Poisson process, can represent the locations of scattered objects such as transmitters in a wireless network, particles colliding into a detector, or trees in a forest.\n",
        "\n",
        "* In all settings, the Poisson point process has the property that each point is stochastically independent to all the other points in the process, which is why it is sometimes called a purely or completely random process.\n",
        "\n",
        "* Despite its wide use as a stochastic model of phenomena representable as points, the inherent nature of the process implies that it does not adequately describe phenomena where there is sufficiently strong interaction between the points. This has inspired the proposal of other point processes, some of which are constructed with the Poisson point process, that seek to capture such interaction.\n",
        "\n",
        "* https://towardsdatascience.com/the-poisson-process-everything-you-need-to-know-322aa0ab9e9a"
      ]
    }
  ]
}